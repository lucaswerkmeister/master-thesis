%% LaTeX2e class for student theses
%% sections/evaluation.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\chapter{Evaluation}
\label{ch:Evaluation}

% TODO write introductory paragraph, once the sections are laid out

% TODO find a better title for this section
\section{Schema Quality}
\label{sec:Evaluation:quality}

In general, the quality of the inferred schemas is satisfactory.
On occasion, parts of the schema may not make sense –
for example, if a shape declares that the value for a \PL{P735}{given name} statement
should be a \QL{Q202444}{given name} or a \QL{Q101352}{family name} –
but these problems are usually not the fault of the inference process,
but rather point to problems in the input data:
in this example, someone probably used an item for a family name
instead of the identical given name. % TODO example!
% TODO more about the schema quality (with examples!)
% TODO elaborate

% TODO find a better title for this section
\section{Duration of the inference process}
\label{sec:Evaluation:duration}

While attempts to validate data against the inferred schema
suffer due to the size of the input data and the schemas,
no such problems appear to plague the inference process,
which, while slow, has a more reliable runtime.
To some degree, this was already apparent in the execution times
of the various jobs that were run on the Wikidata Shape Expressions Inference Tool:
ranging from five or ten minutes to several hours,
they roughly follow the size of the input data linearly.

However, the data from the Wikidata Shape Expressions Inference tool
is not without its problems:
as the tool was tested with different jobs,
various problems were discovered and subsequently fixed
(some of them described in more detail earlier, others too minor to be worth mentioning),
so the runtimes available from the tool apply to a range of software versions,
with several instances of the same job being repeated (to verify a software fix)
with highly different runtimes.
Therefore, a subset of the tool’s jobs was selected
and repeated locally, with a single software version,
to get more reliable execution times.
\Cref{sec:jobs-over-various} contains graphs of runtime over various factors,
which are explained in more detail in the following paragraphs,
each with three different functions fitted to the data:
a simple linear function $a+bx$,
a quadratic function $a+bx+cx^2$,
and a power function $a+bx^c$.
Each figure contains two subfigures,
one for the full data and one with two outlier records removed –
see the text in the appendix for details.

The most obvious possible relation is
to directly compare the runtime to the number of entities selected by the user’s query,
as shown in \cref{fig:jobs-over-entities}.
However, it is clear from the graphs that there is no direct relation
between the number of entities and the runtime,
which is not surprising because the amount of work that RDF2Graph has to do
highly depends on the size of the entities,
as well as the number of entities indirectly selected as the values of statements on the original entities (and their size).

Instead, a much more sensible relation is the total amount of input data:
the number of triples which Fuseki serves to RDF2Graph
(that is, the number of lines in the N-Triples file). % TODO \cref background?
As can be seen in \cref{fig:jobs-over-triples},
this results in a fairly linear relation,
especially if two outliers are removed,
in which case the functions fit the data very well.
However, with the outliers included the fit is much less satisfactory.

\begin{lstfloat}[b]
\begin{lstlisting}[language=awk]
BEGINFILE {
  count = 0;
}

$2 == "<http://www.wikidata.org/prop/direct/P31>" {
  count++;
}

ENDFILE {
  print FILENAME, count
}
\end{lstlisting}
\caption{GNU AWK script to count the number of \PName{wdt:P31} triples in the input.}
\label{listing:P31}
\end{lstfloat}

\begin{lstfloat}[b]
\begin{lstlisting}[language=awk]
BEGINFILE {
  count = 0;
  delete classes;
}

$2 == "<http://www.wikidata.org/prop/direct/P31>" {
  classes[$3]++
}

ENDFILE {
  for (class in classes)
    count++;
  print FILENAME, count;
}
\end{lstlisting}
\caption{GNU AWK script to count distinct classes in the input.}
\label{listing:classes}
\end{lstfloat}

Since RDF2Graph heavily relies on type information,
another possible factor for execution time
is just the number of \PName{wdt:P31} triples in the input,
rather than the overall number of triples.
(Recall that \PL{P31}{instance of} is the Wikidata property linking an item to its class.)
% TODO a) is that “recall” appropriate? b) was that even clearly explained yet?
The number of \PName{wdt:P31} triples was counted
using the GNU AWK snippet found in \cref{listing:P31},
and the result is shown in \cref{fig:jobs-over-P31s}:
the functions are more linear and fit the data better, both with and without outliers.
However, with outliers included the fit is still not completely satisfactory.

Alternatively, instead of counting \PName{wdt:P31} triples
it is also possible to count the distinct number of classes in the input data.
Classes were counted using the GNU AWK snippet found in \cref{listing:classes},
and the result is shown in \cref{fig:jobs-over-classes}:
the functions are significantly less linear now
(though this is not visible in the function equations shown in the graphs, due to rounding),
but they finally fit the data well without excluding the outliers:
in fact, the graph with outliers has slightly better fits than the one without outliers.

Two conclusions are possible from this:
the execution time could derive linearly from the number of input triples or \PName{wdt:P31} triples,
or it could derive nonlinearly from the number of input classes.
The first conclusion has no satisfactory explanation for the outliers
which need to be excluded to get good function fits,
whereas the second conclusion requires no cherry-picking in the data
but lacks an explanation for the nonlinear runtime.
% TODO is this undecidedness between the conclusions acceptable?

% TODO explain more clearly why it’s useful to relate runtime to triples
% even though the triples are not direct user input
% and possible improvements for the tool
% (check git log for the deleted paragraphs on this)

% TODO user feedback for the tool

% TODO unable to validate directly

% TODO useful as a basis for manually assembled schemas (which can then be used to validate)
