%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\chapter{Applying \gls{RDF2Graph} to Wikidata}
\label{ch:RDF2Graph+Wikidata}

This chapter describes the changes that were made to \gls{RDF2Graph} and related software in the course of this thesis.
Some of them are general improvements unrelated to \gls{Wikidata} (\cref{sec:RDF2Graph+Wikidata:updates}),
some are motivated by the \gls{Wikidata} use case but still generally useful (\cref{sec:RDF2Graph+Wikidata:cyclic-graphs,sec:RDF2Graph+Wikidata:schema-reduction,sec:RDF2Graph+Wikidata:depth-limit}),
and some are specific to \gls{Wikidata} and result in a version of \gls{RDF2Graph}
that cannot be used for other RDF graphs (\cref{sec:RDF2Graph+Wikidata:Wikidata}).
All the changes are available in the source code repositories at
\url{https://github.com/lucaswerkmeister/RDF2Graph} and
\url{https://github.com/lucaswerkmeister/RDFSimpleCon},
in the \branchname{master} and \branchname{wikidata} branches;
some of them may also be merged into the upstream \gls{RDF2Graph} and \gls{RDFSimpleCon} repositories in the future.

\section{General \gls{RDF2Graph} Updates}
\label{sec:RDF2Graph+Wikidata:updates}

The \branchname{master} branch of the \gls{RDF2Graph} source code repository
has not seen any updates since 2015 (when \cite{vanDam2015} was published),
so some updates were needed to make the program run on newer software versions
and to target a more recent version of \gls{shex}.
Many of these were rather minor in nature,
but a few of the major ones concerning the \gls{shex} exporter are described in this section.
(I later noticed that the \gls{RDF2Graph} source code repository
also has a \branchname{dev} branch,
which has some more recent changes including a few fixes,
but most of them are not relevant to the issues discussed here.)

The final step of the \gls{shex} export was mostly rewritten from scratch.
This is the step that translates a \gls{json-ld} file describing the \glspl{shape} of the \gls{schema}
into a \gls{shexc} file;
the previous version did this using Jade,
a templating engine for \gls{html} documents (renamed to Pug in 2016),
constructing an \gls{html} document containing a single plain-text \lstinline[language=html]{<pre>} element,
then extracting this text from the document using an \gls{html}-to-text converter.
The new version directly produces the text from \gls{JavaScript}
and includes several improvements:
datatypes are now properly supported,
whereas the previous version only supported a handful of hard-coded \glspl{iri} as datatypes
and exported all other datatypes as if they were actually \glspl{shape};
\glspl{prefix} are used everywhere in the output, highly improving readability;
and the output is sorted, making the whole generation process more deterministic
and thus making it easier to compare the results of multiple inference processes.

The syntax of the generated \gls{shexc} \glspl{schema}
also required some changes.
First, \gls{RDF2Graph} originally targeted \gls{shex} version 1.0
whereas the current release is version 2.0,
which introduced some syntactic changes
(e.~g. replacing some commas with semicolons).
Second, \gls{RDF2Graph} emitted syntax for an experimental, in-progress version of \gls{shex}
with support for inheritance between \glspl{shape}:
if, for example, the inferred \gls{schema} contained classes for both “human” and “person”,
and “human” was a subclass of “person” in the input data set,
then \gls{RDF2Graph} would declare that the “human” \gls{shape} extended the “person” \gls{shape}
and omit \glspl{predicate} from the “person” \gls{shape} in the “human” \gls{shape},
since those would be redundant with the \glspl{predicate} inherited from the “person” \gls{shape}.
This feature has not made it into any released version of \gls{shex} yet
(it can still be found in \branchname{on-shape-expression} branches of related repositories,
though the syntax has slightly changed:
it now uses the keyword \lstinline{EXTENDS} whereas \gls{RDF2Graph} used the symbol \lstinline{&}),
so the \gls{shex} exporter was changed to only mention the parent classes for a \gls{shape} in a comment,
and simplification step 4 (see \cref{sec:Background:RDF2Graph}) was disabled
so that the redundant \glspl{predicate} are included after all,
since they are no longer automatically inherited.

\section{Wikidata Support}
\label{sec:RDF2Graph+Wikidata:Wikidata}

This section outlines the general process that is used when running \gls{RDF2Graph} against data from \gls{Wikidata}
and then describes several changes to \gls{RDF2Graph} that were necessary to support this.
(The subsequent subsections correspond to those changes, not to the individual steps of the process.)

\subsection{Overall process, data download}
\label{subsec:RDF2Graph+Wikidata:Wikidata:download}

Usually, \gls{RDF2Graph} is run against a \gls{sparql} endpoint
which serves the \gls{rdf} graph for which one wants to infer the structure.
However, simply running \gls{RDF2Graph} against \acrfull{wdqs}, the public \gls{sparql} endpoint for \gls{Wikidata},
would mean attempting to infer a \gls{schema} from all of \gls{Wikidata},
which is neither the goal of this thesis
(that is to infer \glspl{schema} from a small set of exemplary \glspl{item})
nor even remotely feasible given the amount of data in \gls{Wikidata}.
For example, the 2018-10-08 full \gls{Wikidata} dump, in \gls{N-Triples} format,
is \SI{1.1}{\tera\byte} large after decompression % 1168298616230 bytes
and contains \num{7523105374} triples.

Instead, a process was set up which,
given a query which selects the exemplary \glspl{item},
downloads the related data for them and runs \gls{RDF2Graph} against it.
The process is outlined in \cref{fig:process}
and controlled by a Makefile in the \gls{RDF2Graph} repository,
so that after creating an \filename{\variable{example}.entities.sparql} file
with a \gls{sparql} query selecting the exemplary items,
it is sufficient to run \command{make \variable{example}.shex}
to run the entire process and generate the \gls{shex} file.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \tikzstyle{file} = [rectangle, draw, rounded corners, text centered]
    \tikzstyle{pipe} = [style=file, dashed]
    \tikzstyle{directory} = [rectangle, draw, text centered]
    \tikzstyle{arrow} = [draw, -latex', right]

    \begin{scope}[node distance=2cm]
      \node[file] (entities) {\filename{\variable{example}.entities.sparql}};
      \node[file, below of=entities] (data) {\filename{\variable{example}.data.sparql}};
      \node[pipe, below of=data] (JSON) {\filename{\variable{example}.json}};
      \node[file, below of=JSON] (N-Triples) {\filename{\variable{example}.nt}};
      \node[directory, below of=N-Triples] (Fuseki) [align=center] {\dirname{\variable{example}-fuseki} \\ \texttt{http://localhost:3030/\variable{example}/query}};
      \node[directory, below of=Fuseki] (RDF2Graph) {\dirname{\variable{example}-results}};
      \node[file, below of=RDF2Graph] (ShEx) {\filename{\variable{example}.shex}};
      \node[file, below of=ShEx] (HTML) {\filename{\variable{example}.html}};
    \end{scope}

    \begin{scope}[every path/.style=arrow, midway]
      \path (entities) -- node {\command{sed}} (data);
      \path (data) -- node {\gls{wdqs}} (JSON);
      \path (JSON) -- node {\command{jq}} (N-Triples);
      \path (N-Triples) -- node {Fuseki} (Fuseki);
      \path (Fuseki) -- node {\gls{RDF2Graph}} (RDF2Graph);
      \path [dashed] (RDF2Graph.north east) to [out=30,in=330,looseness=5] node {\gls{RDF2Graph}, simplify} (RDF2Graph.south east);
      \path (RDF2Graph) -- node {\gls{shex} exporter} (ShEx);
      \path (ShEx) -- node {\command{pygmentize}} (HTML);
    \end{scope}
  \end{tikzpicture}
  \caption{Overview of the process}
  \label{fig:process}
\end{figure}

First, the query selecting the exemplary \glspl{item} is transformed
into a query selecting all the required data,
using the Unix \command{sed} command.
The generated query selects all \glspl{statement} of the exemplary \glspl{item} (“direct \glspl{statement}”),
all \glspl{statement} of \glspl{item} which occur as values of the direct \glspl{statement} (“indirect \glspl{statement}”),
and all \PL{P31}{instance of} \glspl{statement} of \glspl{item} which occur as values of the indirect \glspl{statement}.
This query is run against \gls{wdqs},
which returns the results in \gls{json} format;
they are then piped into a script for the \command{jq} tool (“\gls{json} query”),
which transforms them into \gls{N-Triples} format,
and stored in an \gls{N-Triples} file.

Next, the Apache Jena Fuseki \gls{sparql} server is run locally,
serving the data from this \gls{N-Triples} file.
As soon as it has finished loading the data file,
\gls{RDF2Graph} is run against this local \gls{sparql} endpoint for the main inference process,
including \gls{RDF2Graph}’s simplification step.
Once \gls{RDF2Graph} terminates, the Fuseki server is stopped.

Afterwards, the results from \gls{RDF2Graph} are available as a graph of classes with associated information,
and the \gls{RDF2Graph} \gls{shex} exporter is run to produce a \gls{shex} file.
If desired (\command{make \variable{example}.html}),
that file can also be turned into an \gls{html} file using the Pygments syntax highlighter,
which makes the \gls{shex} code more readable.

\subsection{Type predicates}
\label{subsec:RDF2Graph+Wikidata:Wikidata:predicates}

\Gls{RDF2Graph} heavily relies on the type information of the RDF graph it inspects:
it uses the \PName{rdf:type} \gls{predicate} to map a node to its \gls{shape}
(assuming a one-to-one mapping between classes and \glspl{shape})
and the \PName{rdfs:subClassOf} \gls{predicate} to determine the parent classes of a class,
which are used in the simplification step.
However, \gls{Wikidata} does not use these standard \glspl{predicate}:
the class(es) and superclass(es) of an item
are regular \glspl{statement} like any other \gls{Wikidata} \gls{statement},
using the \glspl{property} \PL{P31}{instance of} and \PL{P279}{subclass of}.
In the \gls{rdf} export, \PName{rdf:type} and \PName{rdfs:subClassOf} are only used
as part of the meta-model,
assigning each item the class \PName{wikibase:Item}, a subclass of \PName{wikibase:Entity}.

To use the type information within the data instead of this meta-model,
the queries which \gls{RDF2Graph} uses to explore the input graph
were changed to use the \glspl{predicate} \PName{wdt:P31} and \PName{wdt:P279}
instead of \PName{rdf:type} and \PName{rdfs:subClassOf}.
(Note that \gls{RDF2Graph} still uses \PName{rdf:type} and \PName{rdfs:subClassOf}
when writing its internal results graph,
so queries operating on that graph as part of the simplification step
still use those \glspl{predicate}.)

\subsection{Data reduction}
\label{subsec:RDF2Graph+Wikidata:Wikidata:reduction}

The \glspl{label}, \glspl{description} and \glspl{alias} of an \gls{item} can make up a large portion of its data,
but are generally not interesting for \gls{shex} \glspl{schema},
since there is rarely more to say about them than
“an \gls{item} has one or more \glspl{label}, zero or more \glspl{description}, and zero or more \glspl{alias}”.
(A manually curated \gls{schema} might go beyond this –
perhaps requiring, for example, that \glspl{item} about Spanish municipalities have a label in Spanish –
but such details are beyond the ability of \gls{RDF2Graph} to infer.)
Additionally, \gls{Wikidata} \glspl{item} often have a number of \glspl{statement} listing external identifiers for the \gls{item}
(that is, identifiers in other databases for the same concept described by this \gls{item}):
for example, \gls{Wikidata}’s \Q{Q80} corresponds to \loc{no99010609} in the \gls{loc},
\viaf{85312226} in \gls{viaf},
\imdbName{nm3805083} in the \gls{imdb},
\TwitterAccount{timberners\_lee} on Twitter,
and dozens of other external identifiers.
All these external identifiers are technically just ordinary \glspl{statement},
but since they carry a rather different kind of information than other \glspl{statement},
they are sorted into a separate section when viewing the \gls{item} on the \gls{Wikidata} website.

In order to reduce the runtime of the \gls{RDF2Graph} inference process,
and to reduce clutter in the inferred \glspl{schema},
the \glspl{label}, \glspl{description}, \glspl{alias}, and external identifiers of an \gls{item}
are excluded when downloading the data for a set of exemplary \glspl{item}:
the generated query selecting the required data
(\filename{\variable{example}.data.sparql} in \cref{fig:process})
only selects triples for statements of non-external identifier properties.

\subsection{Full type hierarchy}
\label{subsec:RDF2Graph+Wikidata:Wikidata:hierarchy}

One undesirable consequence of running \gls{RDF2Graph} against a reduced data set
is that \gls{RDF2Graph} cannot see the full type hierarchy of the classes involved:
for example, depending on how much data was downloaded,
it may or may not be aware that the classes \QL{Q112099}{island nation} and \QL{Q3624078}{sovereign state}
have a common superclass, \QL{Q7275}{state}.
And if \gls{RDF2Graph} does not know that two classes have a common superclass,
it cannot merge them during the simplification step.

To avoid this, an option was added to \gls{RDF2Graph}
which allows specifying an alternative \gls{sparql} endpoint
for all queries that require a full view of the data,
and this alternative endpoint is used for the query to get all parent and child classes of a class.
(If the option is not specified, it falls back to the default \gls{sparql} endpoint.)
The Makefile mentioned in \cref{subsec:RDF2Graph+Wikidata:Wikidata:download}
specifies the \gls{wdqs} \gls{sparql} endpoint for this option,
so that \gls{RDF2Graph} can discover the full class hierarchy around all relevant items
even when running against a subset of \gls{Wikidata}.

\subsection{Simplification}
\label{subsec:RDF2Graph+Wikidata:Wikidata:simplification}

\Gls{RDF2Graph}’s simplification step would originally merge all classes into their superclasses,
almost completely unconditionally,
stopping only at the root class \PName{owl:Thing}.
This works well for \gls{rdf} graphs with a lot of different subclasses directly beneath \PName{owl:Thing},
but is much too aggressive for \gls{Wikidata}:
not only does \gls{Wikidata} have a different root class (\QL{Q35120}{entity}),
but it also has a complex hierarchy of abstract classes below that root class,
and merging other classes into those abstract classes
(like \QL{Q151885}{concept}, \QL{Q7184903}{abstract object} or \QL{Q830077}{subject})
would not result in useful \glspl{schema}.

Therefore, step 2 in the simplification process was adapted
to add a number of \gls{Wikidata} \glspl{item} to the set of classes
which other classes should not be merged into
(originally only containing \PName{owl:Thing}),
and to stop looking for common superclasses of two classes
after walking up five levels in the class hierarchy.
(The limit of five levels is an arbitrary choice
and could also be made configurable if deemed necessary in the future,
but it seems to work out well enough in practice.)

\section{Support for Cyclic Type Hierarchies}
\label{sec:RDF2Graph+Wikidata:cyclic-graphs}

As outlined in \cref{sec:Background:RDF2Graph},
\gls{RDF2Graph} has an optional simplification feature
where the \gls{schema} will be simplified in several steps,
based on the type hierarchy of the classes involved.
For this, the type hierarchy is loaded into an in-memory data structure,
which in the code is referred to as a “tree”.
In fact, the data structure forms a generic, directed graph,
where each node may have any number of children (subclasses) and any number of parents (superclasses),
and no restrictions on the structure are enforced during construction.
However, while the algorithms subsequently operating on the data structure support classes with multiple parent classes,
they do assume that the graph is acyclic,
i.~e., that no class is an indirect subclass of itself.

This assumption makes sense in general,
since a type hierarchy is usually assumed to be acyclic:
if there is a cycle in the subclass relations between a list of classes,
that effectively renders all these classes equivalent,
since any instance of any one of these classes is then also an (indirect) instance of all other classes.
However, experience shows % TODO “experience shows” sounds extremely dodgy
that occasional emergence of subclass cycles is almost unavoidable on \gls{Wikidata}:
any one of the subclass links may appear reasonable for just the two \glspl{item} it connects,
and an editor looking at these \glspl{item} will not necessarily notice that a cycle has been formed,
since the other statements forming the cycle are not visible when looking at these two \glspl{item}.
For example, as of 2018-10-11, % TODO date macro?
there exists a cycle in \gls{Wikidata} in the following classes:
\QL{Q4393498}{representation}, \QL{Q937228}{property}, \QL{Q714737}{category of being},
\QL{Q151885}{concept}, \QL{Q2145290}{mental representation}, \QL{Q4393498}{representation}.
It was first introduced in \wikidataDiff{726473098},
when the parent class of \QL{Q2145290}{mental representation}
was changed from \QL{Q1272626}{representation} to \QL{Q4393498}{representation},
and reinforced in \wikidataDiff{726473565};
the latter revision was later reverted in \wikidataDiff{735108434},
citing the created subclass loop as part of the reason,
but as the first revision was not reverted nor the \gls{item} otherwise edited since then,
the cycle persists so far.
The fact that editors work in different languages,
and different items may share the same label in the same language
(see \Q{Q1272626} and \Q{Q4393498}, both “representation”, above),
contributes to the problem that such cycles can be introduced accidentally
and the correct way to break them is not always obvious.

While, by and large, these cycles are eventually found and fixed by the community,
it is possible that, in the meantime, \gls{RDF2Graph} will run on a subclass graph containing cycles.
Therefore, to make the process more robust,
several algorithms in the simplification step were adjusted to be able to cope with cyclic graphs.
This is valuable even though the results in the cycle may no longer make sense,
since it means that a cycle somewhere in the class hierarchy,
typically among very abstract classes,
will no longer impede simplification in other, more concrete classes,
where simplification is much more useful anyways.
Without these improvements,
if any part of the simplification step failed
(typically with a \lstinline[language=java]{StackOverflowError}),
all simplification results would be lost
and the \gls{shex} export would run on the original, completely unsimplified graph.

\subsection{\FunctionName{GetAllChildren}}
\label{subsec:RDF2Graph+Wikidata:cyclic-graphs:GetAllChildren}

A general component of the new algorithms are methods to get all children and parents of a node,
in a matter that is guaranteed to terminate even if there are cycles among the children or parents.
The method for collecting all child nodes is outlined in \cref{alg:GetAllChildren},
and the method for collecting all parent nodes is completely analogous.
Since each node can only enter the return set once,
the queue only grows when nodes are added to the return set,
and each iteration takes one node from the queue,
the algorithm must eventually exhaust the queue and terminate,
provided that the set of nodes reachable from the initial node is finite.

\begin{algorithm}
  \begin{algorithmic}
    \Function{GetAllChildren}{node}
    \State $\Instruction{initialize \Variable{set} of all children (empty)}$
    \State $\Instruction{initialize working \Variable{queue} of children (empty)}$
    \State $\Instruction{add to \Variable{queue}} \gets \Instruction{direct children of \Variable{node}}$
    \While{$\Variable{queue} \neq \emptyset$}
    \State $\Variable{child} \gets \Instruction{take from \Variable{queue}}$
    \If{$\Variable{child} \not\in \Variable{set}$}
    \State $\Instruction{add to \Variable{set}} \gets \Variable{child}$
    \State $\Instruction{add to \Variable{queue}} \gets \Instruction{direct children of \Variable{child}}$
    \EndIf
    \EndWhile
    \State \Return $\Instruction{\Variable{set}}$
    \EndFunction
  \end{algorithmic}
  \caption{Algorithm to collect all direct and indirect child nodes in a graph}
  \label{alg:GetAllChildren}
\end{algorithm}

\subsection{Counting instances}
\label{subsec:RDF2Graph+Wikidata:cyclic-graphs:count-instances}

With this in place,
it becomes easy to reimplement the method which counts the number of direct and indirect instances of each class,
based on the direct instance counts on each class node.
Previously, the method operated recursively,
aggregating instance counts for each indirect subclass of a class
all the way up to the class itself,
and this recursion would never terminate when encountering a cycle of subclasses.
Instead, the new implementation collects all direct and indirect subclasses up-front using \cref{alg:GetAllChildren}
and then sums up their direct instance counts.

\subsection{Simplification steps 3 and 4}
\label{subsec:RDF2Graph+Wikidata:cyclic-graphs:simplify-step-3+4}

Two steps of the simplification process
remove some of the temporary (added) \glspl{type link} of a node,
based on the temporary \glspl{type link} of its neighboring nodes:
step 3 removes temporary \glspl{type link} from parent classes that are only found in one child class,
and step 4 removes temporary \glspl{type link} from child classes that are made redundant by a \gls{type link} in the parent class.
Both steps were originally implemented as inspecting the neighboring nodes’ temporary \glspl{type link}
and then directly manipulating the node’s own temporary \glspl{type link}.
This required that each step traversed the nodes in the correct order
(parents before children for step 3,
children before parents for step 4)
and was implemented by traversing the graph recursively,
which is problematic if the graph contains cycles.

This problem was solved by splitting up the analysis and modification of the temporary \glspl{type link}:
each step now has two parts,
where the first part marks all temporary \glspl{type link} that should be removed,
and the second part actually removes them from a node’s temporary \glspl{type link}.
As long as the first part (“mark”) for all nodes is run before the second part (“remove”) for any node,
these parts can visit the nodes in any order,
and instead of recursively traversing the graph,
both steps now first collect all child nodes of the root node
and then iterate them twice,
running the first part (“mark”) the first time and the second part (“remove”) the second time.

\subsection{Node distances}
\label{subsec:RDF2Graph+Wikidata:cyclic-graph:distance}

\Gls{RDF2Graph} also has a method to determine the distance of all indirect parents from a certain node,
which is used when searching for common superclasses of a class.
Like the other methods, this was implemented recursively,
setting the distance of a parent node to the current value of a counter
and then calling the same method on all parent nodes of that node with the counter incremented by one.
In this case, the recursion was kept,
but the method was adjusted to only visit a parent node
if it has not been visited before, or if its current distance is larger than the counter value.
The second part of the condition is necessary to ensure that the distance is set correctly
if a node is visited first via a longer path and then later again via a shorter path,
which is possible since the method implements a depth-first search instead of a breadth-first search.

\subsection{Parent check}
\label{subsec:RDF2Graph+Wikidata:cyclic-graph:IsParent}

There is also a method to determine whether a certain node is a (direct or indirect) parent node of another node,
originally implemented recursively.
This was replaced by a version which first retrieves the set of the potential child node’s parent nodes,
using \cref{alg:GetAllChildren},
and then checks whether the potential parent node is an element of it.

\section{Schema Reduction}
\label{sec:RDF2Graph+Wikidata:schema-reduction}

An unexpected problem emerged once the \gls{schema} inference itself was in place:
it proved to be almost impossible to validate \glspl{item} against the inferred \glspl{schema}
for all but the most simple data sets.
Two \gls{shex} implementations were evaluated:
shex.js,
a \gls{JavaScript} implementation running in \gls{Node.js},
and shex-java,
a Java implementation offering two different validation algorithms \cite{boneva:hal-01590350}.
shex.js would usually crash with an out-of-memory error from \gls{Node.js} within a few minutes,
whereas shex-java would run for hours on end without any output or apparent progress
(with either algorithm).

One attempted strategy to be able to validate the inferred \glspl{schema}
was to reduce the size of the \glspl{schema} by dropping some less-relevant elements.
This was part of the motivation for dropping \glspl{label}, \glspl{description}, \glspl{alias}, and external identifiers of an \gls{item}
from the data set that the inference would be run against
(see \cref{subsec:RDF2Graph+Wikidata:Wikidata:reduction});
however, reducing the input data set is not the only way to reduce the resulting \gls{schema}:
it is also possible to further trim the \gls{schema} after the inference process has finished.
This was implemented in the final step of the \gls{shex} exporter,
the \filename{shexbuilder.js} program,
which had already been mostly rewritten for different reasons
(see \cref{sec:RDF2Graph+Wikidata:updates}).

Elements can be removed from a \gls{schema} on three different levels:
an individual \gls{type link} can be removed from a \gls{predicate},
a \gls{predicate} can be removed from a \gls{shape},
or an entire \gls{shape} can be removed from the \gls{schema}.
In each case, the decision on whether to keep or drop the element
requires an assessment of whether the element \emph{can} be dropped,
and whether it \emph{should} be dropped.

\Glspl{shape} can be removed from a \gls{schema} as long as they are not referenced by any other shape,
and as long as they are not interesting as “entry points” for the \gls{schema}
(i.~e., \glspl{shape} to validate the initial \gls{focus node} against).
The second condition is subjective,
but in practice, \glspl{shape} that are interesting as “entry points”
are usually also referred to by other \glspl{shape},
so the condition can be ignored.
The first condition is implemented in the exporter
by maintaining two sets of \glspl{shape}:
one for \glspl{shape} which are referenced from \glspl{type link},
and one for \glspl{shape} which should perhaps be dropped.
When printing the final \gls{schema},
only \glspl{shape} found in the latter set but not in the former are skipped.

\Glspl{predicate} can be removed from a \gls{shape} unconditionally:
since the \glspl{shape} produced by \gls{RDF2Graph} are not closed,
removing a \gls{predicate} from a \gls{shape} means that \glspl{triple} using that \gls{predicate}
will now be ignored by the validator when testing against the \gls{shape}.
However, a \gls{shape} without \glspl{predicate} is hardly useful,
so a balance needs to be struck when deciding whether a \gls{predicate} \emph{should} be dropped.

Individual \glspl{type link} can, in principle, never be removed from a \gls{predicate}:
if a \gls{type link} occurs in the \gls{schema},
then there must have been a corresponding \gls{triple} in the input data,
and removing the \gls{type link} would turn that \gls{triple} into a violation,
at least if simplification was applied to the \gls{schema}.
(Without simplification, some \glspl{type link} may be redundant
due to other \glspl{type link} for related classes.)
However, this assumes a perfect input data set which should not have any violations,
which is an unrealistic assumption at least for \gls{Wikidata} input data:
even if the exemplary input \glspl{item} were carefully selected
and have no incorrect \glspl{statement} themselves,
it is unlikely that all the \glspl{item} which those \glspl{item} link to are also flawless.
(See \cref{sec:Evaluation:quality} for an example of problems in a high-profile input data set.)
Given this situation, it is defensible to drop \glspl{type link}
which are likely to reflect errors in the input data.

The decision whether to drop an element or not
is implemented as a simple numeric threshold on all three levels.
\Gls{RDF2Graph} tracks the number of instances of each class it encounters,
and this information is still available to the \gls{shex} exporter,
which can therefore drop \glspl{type link} that are used less than $m$ times,
\glspl{predicate} that are used less than $n$ times (sum of all \gls{type link} uses),
and \glspl{shape} for classes with less than $o$ instances.
The three limits are independent,
though in practice it makes most sense to choose them such that $m > n > o$.
An alternative strategy to explore in the future might be
to turn those fixed thresholds into ratios,
so that the same parameters can be used for vastly different data sets
with varying numbers of class instances overall.

Unfortunately, this strategy was not very successful in enabling validation of the \glspl{schema}.
Only at almost draconian thresholds for dropping elements,
where only a few \glspl{shape} and \glspl{predicate} would remain in the \gls{schema},
would validation succeed;
manual bisecting of the \glspl{schema} which failed to validate
would often turn up a fairly small problematic part of a \gls{schema}
which a simple count-based threshold was ill-suited to detect automatically.
Therefore, while the code implementing the limits remains in place,
all three are disabled by default.

\section{Depth Limits in Validation}
\label{sec:RDF2Graph+Wikidata:depth-limit}

Another attempt to make validation of the inferred \glspl{schema} more feasible
was to limit the maximum depth during the validation process.
Consider, for example, a simple \gls{shape} for humans,
which describes a human as having any number of human parents and a date of birth.
To validate whether any given node is actually a human,
all its direct and indirect parents must also be validated,
potentially thousands of ancestors, no matter how remote.
If the \gls{shape} is more complicated,
with more predicates potentially linking to other \glspl{shape} as well,
this can get very expensive rather quickly.
On the other hand, it is not clear that the more remote validations here are useful,
at least in the context of validating \gls{Wikidata} \glspl{item}
(where different areas of \glspl{item} may be edited by very different sets of editors)
against automatically inferred \glspl{schema}
(which are likely to have inherited some imperfections from the input data):
experience shows that % TODO is “experience shows” acceptable?
most inferred \glspl{schema} tend to include \glspl{shape} for certain core classes,
e.~g. \QL{Q5}{human} or \QL{Q3624078}{sovereign state},
but someone attempting to validate an \gls{item} for a mammalian protein
is unlikely to care that the \gls{item} for the protein’s discoverer’s husband’s country of citizenship
happens to be missing an \PL{P1279}{inflation rate} statement.

Therefore, in an attempt to reduce the amount of irrelevant violations
and to make the validation terminate without crashing,
a patch to add an optional depth limit to the shex.js implementation was developed.
With this change, if the depth limit was reached,
the validator would skip recursing into another \gls{shape}
and instead only record the fact that the limit was reached before continuing.

Unfortunately, however, this proved unsuccessful.
When testing some \glspl{item} against several inferred \glspl{schema},
low limits (2–4) would yield unpredictable results
(sometimes validate successfully, sometimes report problems, sometimes crash),
whereas higher limits (up to 10) would typically have the same result as validation without any depth limit
(either validation failure or crash),
though sometimes with wildly varying runtimes.
(More details can be found in \cref{sec:appendix:depth-limit}.)
One possible explanation for this is that pruning one part of the validation process when reaching the depth limit
may cause the validator to spend more time in other areas,
which may previously not have been necessary if the pruned part would otherwise have resulted in a violation.

\chapter{The Wikidata Shape Expressions Inference Tool}
\label{ch:wdsi}

This chapter describes the major user-facing result of this thesis:
the \gls{wdsi},
which makes the version of \gls{RDF2Graph} adapted to \gls{Wikidata}
easily available to \gls{Wikidata} editors.
This includes the general design and implementation of the tool (\cref{sec:wdsi:abstract}),
some specifics to make it run on the \gls{Wikimedia Toolforge} platform (\cref{sec:wdsi:Toolforge}),
and a few utilities to make it more pleasant to use (\cref{sec:wdsi:utilities}).
The tool is online at \url{https://tools.wmflabs.org/wd-shex-infer/}
and its source code may be found at \url{https://phabricator.wikimedia.org/source/tool-wd-shex-infer/}.

\section{General Design and Implementation}
\label{sec:wdsi:abstract}

The goal of the tool is to make the \gls{schema} inference process available to other \gls{Wikidata} editors,
which is necessary because \gls{RDF2Graph}, its \gls{shex} exporter, and the Makefile-based process around them
require several different programs and programming runtimes to be available,
which it would be unreasonable to expect every interested user to install
(not to mention that the Makefile assumes a Unix-like environment,
whereas the potential users are likely to use Windows).
Installing such a program on \gls{Wikimedia Toolforge}
and making it available to users via a web interface
is a common approach in the \gls{Wikimedia} universe.

\begin{figure}
  \includegraphics[width=\textwidth]{screenshots/wdsi-index}
  \caption{Index page of the \gls{wdsi}}
  \label{fig:wdsi-index}
\end{figure}

\begin{figure}
  \includegraphics[width=\textwidth]{screenshots/wdsi-zika}
  \caption{Detail page for \wdsiJob{37}}
  \label{fig:wdsi-zika}
\end{figure}

In this \gls{Wikimedia}-hosted tool,
users enter a \gls{sparql} query selecting the set of exemplary \glspl{item} from which to infer a \gls{schema},
and the tool downloads the associated data,
run \gls{RDF2Graph} and the \gls{shex} exporter,
and makes the \gls{shexc} output available to the user.
The simplest process for that would be
to directly return the \gls{shexc} code in the server’s response to the user’s \gls{http} request,
but that is not possible:
even simple inference \glspl{job}
from a single \gls{item} take at least several minutes,
and more complicated \glspl{job}
over several dozens of \glspl{item} can take multiple hours –
the connection to the user would time out long before that,
and the user might also become impatient and simply close their browser window or tab.

Instead, the inference process runs in the background,
and after submitting the \gls{sparql} query and starting the process,
the user is redirected to a page describing the currently running \gls{job}.
They can periodically reload the page,
and each time the page is loaded,
the tool checks if the background process is still running.
If the background process has finished in the meantime,
the tool collects the output,
cleans up the temporary files left behind by the process,
and finally makes the output
(primarily the \gls{shexc} code, but also debugging outputs)
available to the user.

Since this already more or less requires storing inputs and outputs persistently,
a natural extension of this scheme is to make this \gls{job} page available to others,
so that not only the original submitter but also other users can inspect a running or completed \gls{job}.
(The input data is entirely public data from \gls{Wikidata},
so there is no reason to restrict the visibility of the outputs.)
This facilitates easy collaboration on \glspl{schema} between multiple users
and allows even casual visitors to see how the tool operates,
and what kinds of results it produces,
without having to start their own inference process.
To make each result easier to comprehend for others,
users can also submit a title, description, and/or \gls{url} for additional information
along with their \gls{sparql} query.
\Cref{fig:wdsi-zika} shows the page for one finished \gls{job},
with its title, description, and \gls{url} (the “more information” link,)
and \cref{fig:wdsi-index} shows the index page of the tool,
listing all the finished jobs that were submitted.
(At the time of taking the screenshot,
no jobs were currently running,
otherwise they would also be listed.)

As the inference process consumes a lot of resources,
it does not run directly on the same system as the web server providing the tool’s front-end.
Instead, it is submitted as a job for the Sun Grid Engine system also offered by the \gls{Wikimedia Toolforge} environment,
where it will be run on some execution host with sufficient free resources.
To ensure that the system’s resources are not exhausted by this one tool,
the tool only allows at most two \glspl{job} to run in parallel,
and prevents users from submitting any more \glspl{job} if too many \glspl{job} are currently running,
instead asking them to try again later.
\Gls{job} submission is also restricted to users with a valid \gls{Wikidata} account,
authenticated via OAuth.
The identity of the submitting user is another attribute of a \gls{job},
along with its title, description, \gls{url}, and \gls{sparql} query,
and can be seen by other users who look at the pending or finished \glspl{job} of the tool.

Details of each \gls{job},
such as its title, submitting user, and submission time,
are stored in a tool-specific SQL database on the \gls{Wikimedia Toolforge} database servers.
However, the outputs of a \gls{job}
(\gls{shexc} file, standard output of the process, standard error of the process),
as well as to a lesser degree the \gls{sparql} query forming its input,
are too large to store in a database.
Instead, they are stored directly on the file system.

\section{Utilities} % TODO Schema Reading Utilities? HTML Utilities?
\label{sec:wdsi:utilities}

To make the \gls{shex} output more readable,
support for the \gls{shexc} syntax was added to the popular Pygments syntax highlighter
(\href{https://bitbucket.org/birkenfeld/pygments-main/pull-requests/770}{Pygments pull request \#770}).
If the \gls{shex} code for a \gls{job}
is requested by a browser
or some other kind of client which declares that it can accept HTML
(using \gls{http} content negotiation),
the tool applies the Pygments syntax highlighter to the code on-the-fly
and sends a complete \gls{html} document containing the prettified code and associated \gls{css} rules.
Clients which do not accept \gls{html} documents receive the plain \gls{shexc} code instead.

The \gls{html} document that is sent to browsers
also includes a client-side script,
which searches for \gls{Wikidata} \glspl{item ID} in the \gls{shexc} code,
fetches the \glspl{label} of all mentioned \glspl{item ID} from \gls{Wikidata},
and adds them to the document in \lstinline[language=html]{<abbr>} abbreviation elements.
It also hyperlinks each reference of a \gls{shape} to its definition,
and the definition to the corresponding \gls{item} on \gls{Wikidata}.
This makes it much more convenient to read the \gls{schema} in the browser:
the user merely has to hover their mouse over a class to see its \gls{label} instead of the \gls{item ID};
clicking on it brings the user to the \gls{shape} for that class;
and clicking on the ID there brings the user to the \gls{Wikidata} page for the class,
where they can further explore the related data.

A comparison of the effects of these two features
can be seen in \cref{fig:shexc-syntax-highlighting}.

% TODO revisit layout of this figure when the thesis is close to done,
% perhaps adjust the widths and/or trimming depending on how the figure fits on a page
\begin{figure}[t]
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[trim={0 2.5cm 0 0},clip]{screenshots/shexc-no-syntax-highlighting}
    \caption{
      Excerpt of an inferred \gls{schema} for Linux distributions
    }
    \label{fig:shexc-syntax-highlighting-without}
  \end{subfigure}
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[trim={0 2.5cm 0 0},clip]{screenshots/shexc-with-syntax-highlighting}
    \caption[The same \gls{schema} with syntax highlighting and the script applied]{
      The same \gls{schema} with syntax highlighting and the script applied –
      the cursor is over the \lstinline{P277} \gls{property ID}
    }
    \label{fig:shexc-syntax-highlighting-with}
  \end{subfigure}
  \caption{
    Screenshots showing the effects of syntax highlighting and the client-side script
  }
  \label{fig:shexc-syntax-highlighting}
\end{figure}

\section{\gls{Wikimedia Toolforge} Support}
\label{sec:wdsi:Toolforge}

Since \gls{Wikimedia Toolforge} runs on a rather old Linux distribution
(Ubuntu 14.04 “Trusty Tahr”, originally released April 2014),
the versions of various software used by \gls{RDF2Graph} and the rest of the inference process
were too outdated to use out-of-the-box.
The response to this was twofold:
to cope with older software versions where feasible,
and to install newer software versions where not.

\Gls{RDF2Graph} required Java 8,
but only Java 7 is installed on \gls{Wikimedia Toolforge}.
Fortunately, \gls{RDF2Graph} only used Java 8 for syntactic constructs (“lambda” syntax)
and those only sparingly, so it was not too much work to make it compatible with Java 7 again.
Similarly, Apache Jena and Fuseki have required Java 8 for some time already,
but fortunately \gls{RDF2Graph} is compatible with their older versions which support Java 7,
and which could therefore be installed.

On the other hand, there is no obvious way to make the \command{jq}-based part of the data download step
work with \command{jq} version 1.4, which has no general string replacement capabilities.
Therefore, \command{jq} version 1.5 was installed locally into the tool’s home directory –
as was the latest version of \gls{Node.js}, which was similarly outdated.
(The Pygments syntax highlighter mentioned in \cref{sec:wdsi:utilities} was also installed locally,
since \gls{shexc} syntax support is not yet available in any released version.)

Full installation instructions may be found in the \filename{README} file of the source code repository.
