%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\chapter{Conclusion}
\label{ch:Conclusion}

The goal of this thesis was to investigate how \gls{shex} schemas can be automatically inferred for Wikidata,
and how useful the resulting schemas are.
This was done using an updated and adapted version of the RDF2Graph software,
which was made available to the Wikidata community
through a new web-based tool.

In addition to the changes specific to Wikidata,
many general improvements to RDF2Graph were made over the course of this thesis,
making it easier to use and more robust on any graph.
All these changes are available under the same free software license as the original RDF2Graph,
and I hope that some of them will be included in the original source code repository in the future.

When attempting to validate other items against the inferred schemas,
an unexpected problem arose:
none of the existing \gls{shex} validators were able to reliably perform the validation without crashing.
Several strategies were attempted to remediate this,
both in the schema extraction and in the validators,
but this was ultimately unsuccessful.

However, this does not mean the schemas are not useful.
Sometimes, problems in the input data can manifest themselves
in the form of unusual predicates or target classes in a schema,
which an attentive reader can notice and trace back to the problematic items in the input.
And the full, automatically inferred schemas
can also form the basis for shorter schemas manually extracted from the longer ones,
which can either be validated directly
(now without problems from the validators)
or be further refined by data model experts, % TODO “data model experts” sounds weird
making the automatically inferred schemas a useful basis for manually curated schemas.

% TODO next steps / future work
% * operate on full statements
% * some next steps for tool, see tool chapter
% * rewrite rest of ShEx export – we spend half of our wall-clock time (and even more of our CPU time?) there, doing what feels like not very much to the JSON
% * find other ways to make validation work
% * further improve simplification
%   * when to merge classes
%   * throw away rarely used classes?

% TODO finish off conclusion?
% TODO conclusion should probably be longer
